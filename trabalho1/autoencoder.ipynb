{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## João Pedro Rodrigues Freitas - 11316552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Fazer os mini batches (train, test)\n",
    "- Fazer o one-hot\n",
    "- Fazer normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, X: np.ndarray) -> None:\n",
    "        self.data = X\n",
    "\n",
    "    def getData(self) -> np.ndarray:\n",
    "        return self.data\n",
    "\n",
    "    def setTrainRatio(self, ratio: float) -> None:\n",
    "        self.train_ratio = ratio\n",
    "\n",
    "    def getTrainRatio(self) -> float:\n",
    "        return self.train_ratio\n",
    "    \n",
    "    def getAttrSize(self) -> int:\n",
    "        return self.data.shape[1]\n",
    "    \n",
    "    def shuffleData(self) -> None:\n",
    "        self.data = np.random.permutation(self.data)\n",
    "\n",
    "    def getTrainData(self) -> np.ndarray:\n",
    "        return self.data[:int(self.data.shape[0] * self.train_ratio)]\n",
    "    \n",
    "    def getTestData(self) -> np.ndarray:\n",
    "        return self.data[int(self.data.shape[0] * self.train_ratio):]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        '''Normaliza cada atributo para o intervalo [0, 1]'''\n",
    "        for i in range(self.getAttrSize()):\n",
    "            self.data[:,i] = (self.data[:,i] - np.min(self.data[:,i])) / (np.max(self.data[:,i]) - np.min(self.data[:,i]))\n",
    "    \n",
    "    # def plotData(self) -> None:\n",
    "    #     if self.getAttrSize() != 2:\n",
    "    #         raise ValueError(\"The number of attributes must be 2\")\n",
    "        \n",
    "    #     plt.scatter(self.data[:,0], self.data[:,1], c=self.data[:,-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "\n",
    "    def __init__(self, layers: int, neuronsByLayer: list, data: Data) -> None:\n",
    "        if len(neuronsByLayer) != layers:\n",
    "            raise ValueError(\"The size of the list must be equal to the number of layers\")\n",
    "\n",
    "        # [input, hidden1, hidden2, ..., latentSpace]\n",
    "        self.layers = layers\n",
    "        self.neurons = neuronsByLayer\n",
    "        self.data = data\n",
    "\n",
    "        # camada inicial\n",
    "        self.W = [np.random.rand(data.getAttrSize(), self.neurons[0]) - 0.5]\n",
    "        self.b = [np.random.rand(1, self.neurons[0]) - 0.5]\n",
    "\n",
    "        # camadas ocultas\n",
    "        for i in range(1, self.layers):\n",
    "            self.W.append(np.random.rand(self.neurons[i-1], self.neurons[i]) - 0.5)\n",
    "            self.b.append(np.random.rand(1, self.neurons[i]) - 0.5)\n",
    "\n",
    "        # TODO: parte do decoder\n",
    "\n",
    "    def getLayers(self) -> int:\n",
    "        return self.layers\n",
    "\n",
    "    def getNeuronsByLayer(self) -> list[int]:\n",
    "        return self.neurons\n",
    "    \n",
    "    def getNeuronsOfLayer(self, layer: int) -> int:\n",
    "        return self.neurons[layer]\n",
    "    \n",
    "    def sigmoid(self, Z: np.ndarray) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def der_sigmoid(self, Z: np.ndarray) -> np.ndarray:\n",
    "        f = self.sigmoid(Z)\n",
    "        return f * (1 - f)\n",
    "    \n",
    "    def getWeights(self) -> list[np.ndarray]:\n",
    "        return self.W\n",
    "    \n",
    "    def getBiases(self) -> list[np.ndarray]:\n",
    "        return self.b\n",
    "    \n",
    "    def getZ(self) -> list[np.ndarray]:\n",
    "        return self.Z\n",
    "    \n",
    "    def getA(self) -> list[np.ndarray]:\n",
    "        return self.A\n",
    "    \n",
    "    def getdZ(self) -> list[np.ndarray]:\n",
    "        return self.dZ\n",
    "    \n",
    "    def getdW(self) -> list[np.ndarray]:\n",
    "        return self.dW\n",
    "    \n",
    "    def getdb(self) -> list[np.ndarray]:\n",
    "        return self.db\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> None:\n",
    "        self.Z = [X] # Z[0] é o input\n",
    "        self.A = [X] # A[0] é o input\n",
    "\n",
    "        for i in range(self.layers):\n",
    "            Z = np.dot(self.A[i], self.W[i]) + self.b[i]\n",
    "\n",
    "            if i == self.layers - 1:\n",
    "                A = self.softmax(Z.T)\n",
    "            else:\n",
    "                A = self.sigmoid(Z)\n",
    "\n",
    "            self.Z.append(Z)\n",
    "            self.A.append(A)\n",
    "\n",
    "    def backward(self, Y: np.ndarray) -> None:\n",
    "        # TODO: conferir esse dZ se é 2*(A - Y)\n",
    "        n = Y.shape[0]\n",
    "\n",
    "        self.dZ = [2 * (self.A[-1] - Y)] # erro da camada de saída\n",
    "        self.dW = [np.dot(self.dZ[-1], self.A[-2]) / n]\n",
    "        self.db = [np.sum(self.dZ[-1], axis=1, keepdims=True) / n]\n",
    "\n",
    "        for i in range(self.layers-1, 0, -1):\n",
    "            print(\"Layer: \", i)\n",
    "            self.dZ.append(np.dot(self.W[i], self.dZ[-1]) * self.der_sigmoid(self.Z[i].T))\n",
    "            self.dW.append(np.dot(self.dZ[-1], self.A[i-1]))\n",
    "            self.db.append(np.sum(self.dZ[-1], axis=1, keepdims=True))\n",
    "\n",
    "    def adjustParams(self, lr: float) -> None:\n",
    "        reverseDw = self.dW[::-1]\n",
    "        reverseDb = self.db[::-1]\n",
    "\n",
    "        for i in range(self.layers):\n",
    "            self.W[i] -= lr * reverseDw[i].T\n",
    "            self.b[i] -= lr * reverseDb[i].T\n",
    "\n",
    "    def get_preds(self, y):\n",
    "        return np.argmax(y, axis=0)\n",
    "    \n",
    "    def getAccuracy(self, y_hat, y):\n",
    "        return np.sum(y_hat == y) / y.size\n",
    "    \n",
    "    def fit(self, lr: float = 0.01, n_epochs: int = 100) -> None:\n",
    "        for epoch in range(n_epochs):\n",
    "            self.forward(self.data.getTrainData()[:,:-1])\n",
    "            self.backward(self.data.getTrainData()[:,-1])\n",
    "            self.adjustParams(lr)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch: {epoch}\")\n",
    "                y_hat = self.get_preds(self.A[-1])\n",
    "                y_pred = self.data.getTrainData()[:,-1]\n",
    "                print(f\"Loss: {np.mean(np.square(self.data.getTrainData()[:,-1] - self.A[-1]))}\")\n",
    "                print(f\"Accuracy: {self.getAccuracy(y_hat, y_pred)}\")\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.forward(X)\n",
    "        return self.A[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "\n",
    "    def __init__(self, inputDim: int, hiddenLayers: int, neuronsPerLayer: list[int]) -> None:\n",
    "        if len(neuronsPerLayer) != hiddenLayers:\n",
    "            raise ValueError(\"The size of the list must be equal to the number of hidden layers\")\n",
    "\n",
    "        self.inputDim = inputDim\n",
    "        self.hiddenLayers = hiddenLayers\n",
    "        self.neuronsPerLayer = neuronsPerLayer\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        self._initParams()\n",
    "\n",
    "    def _initParams(self) -> None:\n",
    "        # layersDim = [input, hidden1, hidden2 (latentSpace), hidden1, output]\n",
    "        layersDim = [self.inputDim] + self.neuronsPerLayer + self.neuronsPerLayer[::-1][1:] + [self.inputDim]\n",
    "\n",
    "        for i in range(1, len(layersDim)):\n",
    "            # inicializa com distribuição uniforme entre -0.5 e 0.5\n",
    "            self.W.append(np.random.rand(layersDim[i-1], layersDim[i]) - 0.5)\n",
    "            self.b.append(np.random.rand(1, layersDim[i]) - 0.5)\n",
    "\n",
    "        print(self.W)\n",
    "    \n",
    "    def _sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _der_sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def encode(self, x: np.ndarray) -> np.ndarray:\n",
    "        a = x\n",
    "        for i in range(self.hiddenLayers + 1):\n",
    "            z = np.dot(a, self.W[i]) + self.b[i]\n",
    "            a = self._sigmoid(z)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def decode(self, x: np.ndarray) -> np.ndarray:\n",
    "        a = x\n",
    "\n",
    "        for i in range(self.hiddenLayers + 1, 2 * self.hiddenLayers + 1):\n",
    "            print(i)\n",
    "            z = np.dot(a, self.W[i]) + self.b[i]\n",
    "            a = self._sigmoid(z)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, lr: float = 0.01, n_epochs: int = 100):\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Forward\n",
    "            encoded = self.encode(x)\n",
    "            decoded = self.decode(encoded)\n",
    "\n",
    "            # \n",
    "            # loss = np.mean(np.square(decoded - x))\n",
    "            # err = 2 * (decoded - x)\n",
    "\n",
    "            # # Backward\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # # Backward\n",
    "            # error = decoded - x\n",
    "            # delta = error * self._der_sigmoid(decoded)\n",
    "            # deltas = [delta]\n",
    "            # for i in range(self.hiddenLayers, 0, -1):\n",
    "            #     delta = np.dot(deltas[-1], self.W[i].T) * self._der_sigmoid(encoded)\n",
    "            #     deltas.append(delta)\n",
    "\n",
    "            # deltas = deltas[::-1]\n",
    "\n",
    "            # # Update weights\n",
    "            # for i in range(self.hiddenLayers + 1):\n",
    "            #     self.W[i] -= lr * np.dot(x.T, deltas[i])\n",
    "            #     self.b[i] -= lr * np.sum(deltas[i], axis=0, keepdims=True)\n",
    "\n",
    "            # for i in range(self.hiddenLayers + 1, 2 * self.hiddenLayers + 1):\n",
    "            #     self.W[i] -= lr * np.dot(encoded.T, deltas[i])\n",
    "            #     self.b[i] -= lr * np.sum(deltas[i], axis=0, keepdims=True)\n",
    "\n",
    "            # print(f\"Epoch: {epoch} - Loss: {loss}\")\n",
    "            # print(self.W)\n",
    "            # print(self.b)\n",
    "            # print(\"\")\n",
    "            \n",
    "    \n",
    "    # def fit(self, x, lr=0.01, n_epochs=100):\n",
    "    #     for epoch in range(n_epochs):\n",
    "    #         a = x\n",
    "    #         a_list = [a]\n",
    "    #         z_list = [a]\n",
    "    #         for i in range(self.hiddenLayers + 1):\n",
    "    #             z = np.dot(a, self.W[i]) + self.b[i]\n",
    "    #             a = self._sigmoid(z)\n",
    "    #             a_list.append(a)\n",
    "    #             z_list.append(z)\n",
    "            \n",
    "    #         for i in range(self.hiddenLayers + 1, 2 * self.hiddenLayers + 1):\n",
    "    #             z = np.dot(a, self.W[i]) + self.b[i]\n",
    "    #             a = self._sigmoid(z)\n",
    "    #             a_list.append(a)\n",
    "    #             z_list.append(z)\n",
    "            \n",
    "    #         # calcula o erro\n",
    "    #         loss = np.mean(np.square(x - a))\n",
    "    #         print(f\"Epoch: {epoch} - Loss: {loss}\")\n",
    "            \n",
    "    #         # calcula os deltas\n",
    "    #         delta = 2 * (a - x) * self._der_sigmoid(a_list[-1])\n",
    "    #         deltas = [delta]\n",
    "    #         for i in range(self.hiddenLayers, 0, -1):\n",
    "    #             delta = np.dot(deltas[-1], self.W[i].T) * self._der_sigmoid(a_list[i])\n",
    "    #             deltas.append(delta)\n",
    "            \n",
    "    #         deltas = deltas[::-1]\n",
    "            \n",
    "    #         # atualiza os pesos\n",
    "    #         for i in range(self.hiddenLayers + 1):\n",
    "    #             self.W[i] -= lr * np.dot(a_list[i].T, deltas[i])\n",
    "    #             self.b[i] -= lr * np.sum(deltas[i], axis=0, keepdims=True)\n",
    "            \n",
    "    #         for i in range(self.hiddenLayers + 1, 2 * self.hiddenLayers + 1):\n",
    "    #             self.W[i] -= lr * np.dot(a_list[i].T, deltas[i])\n",
    "    #             self.b[i] -= lr * np.sum(deltas[i], axis=0, keepdims=True)\n",
    "            \n",
    "    #         print(self.W)\n",
    "    #         print(self.b)\n",
    "    #         print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    X = np.vstack([np.random.normal(1, 0.5, [100,10]),\n",
    "                   np.random.normal(-2, 1, [100,10]),\n",
    "                   np.random.normal(3, 0.75, [100,10])])\n",
    "\n",
    "    data = Data(X)\n",
    "    \n",
    "    data.normalize()\n",
    "    data.shuffleData()\n",
    "    data.setTrainRatio(0.8)\n",
    "\n",
    "    inputDim = data.getAttrSize()\n",
    "    hiddenLayers = 2\n",
    "    neuronsPerLayer = [5, 3] # Dimensão latente é a ultima camada oculta\n",
    "    # [10, 5, 3, 5, 10]\n",
    "    \n",
    "    autoencoder = Autoencoder(inputDim, hiddenLayers, neuronsPerLayer)\n",
    "    autoencoder.fit(data.getTrainData(), lr = 0.01, n_epochs = 100)\n",
    "\n",
    "    # ae = Autoencoder(2, [10, 3], data) # len([input, hidden1, hidden2, ..., latentSpace])\n",
    "\n",
    "    # ae.forward(data.getTrainData()[:,:-1])\n",
    "    # ae.backward(data.getTrainData()[:,-1])\n",
    "    # ae.adjustParams(0.05)\n",
    "\n",
    "\n",
    "    # print(ae.getWeights()[0].shape) # w1\n",
    "    # print(ae.getBiases()[0].shape) # b1\n",
    "    # print(ae.getWeights()[1].shape) # w2\n",
    "    # print(ae.getBiases()[1].shape) # b2\n",
    "    # print(ae.getZ()[1].shape) # O1\n",
    "    # print(ae.getA()[1].shape) # A1\n",
    "    # print(ae.getZ()[2].shape) # O2\n",
    "    # print(ae.getA()[2].shape) # A2\n",
    "\n",
    "\n",
    "    # print(ae.getdW()[1].shape) # dW1\n",
    "    # print(ae.getdb()[1].shape) # db1\n",
    "    # print(ae.getdW()[0].shape) # dW2\n",
    "    # print(ae.getdb()[0].shape) # db2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ae.fit(lr = 0.05, n_epochs = 200)\n",
    "\n",
    "    # y_hat = ae.predict(data.getTestData()[:,:-1])\n",
    "    # print(ae.getAccuracy(y_hat, ae.get_preds(data.getTestData()[:,-1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.15459429,  0.0899398 , -0.37538827,  0.21014735,  0.43031858],\n",
      "       [-0.19920491,  0.30950532,  0.4749302 , -0.18516199, -0.34896075],\n",
      "       [ 0.46485666,  0.1242544 , -0.33730847,  0.08141972, -0.07104045],\n",
      "       [-0.43659876,  0.39311029,  0.3354205 , -0.29398829,  0.33445697],\n",
      "       [ 0.28824607,  0.24147265, -0.26062148, -0.46254485,  0.31806867],\n",
      "       [ 0.28704131, -0.30544349, -0.23599799, -0.2560688 ,  0.02361333],\n",
      "       [ 0.22764095, -0.221249  , -0.31868874,  0.21811137,  0.43768673],\n",
      "       [-0.13571291, -0.01671031,  0.41388737,  0.27256543, -0.32503961],\n",
      "       [-0.2948496 , -0.44640027, -0.22974705, -0.0266718 , -0.19580032],\n",
      "       [-0.02864194,  0.11603893,  0.43087347,  0.42349679,  0.12226805]]), array([[-0.44139401, -0.14647768,  0.45454106],\n",
      "       [-0.27545203, -0.18978752, -0.20715384],\n",
      "       [ 0.20136612,  0.23501206, -0.05568166],\n",
      "       [ 0.4128185 ,  0.22524653,  0.38797923],\n",
      "       [ 0.35209704,  0.27259301, -0.17906927]]), array([[ 0.25293974,  0.31063947, -0.10047331, -0.12679718, -0.18420686],\n",
      "       [-0.06691654,  0.37188793, -0.49808552,  0.05006618, -0.27630791],\n",
      "       [ 0.07365206, -0.41377937, -0.41529121, -0.31001348,  0.48505532]]), array([[-0.03773159, -0.11516923, -0.25876374, -0.41554884,  0.18618965,\n",
      "        -0.32275014, -0.0745048 ,  0.08724757, -0.35314386,  0.09735969],\n",
      "       [-0.1378255 , -0.24439765,  0.04859911,  0.4890597 ,  0.26858635,\n",
      "        -0.21474354,  0.0015358 , -0.09392942,  0.02546066,  0.19154889],\n",
      "       [ 0.28774165,  0.45578337, -0.2049419 , -0.17574474, -0.47762382,\n",
      "        -0.20033802,  0.44170908,  0.33339954, -0.38101355,  0.46463994],\n",
      "       [ 0.38791071,  0.35809372,  0.42398205,  0.03398786,  0.47095672,\n",
      "        -0.47380301,  0.06242988, -0.12690503,  0.06406706,  0.39836541],\n",
      "       [-0.05063461, -0.27254789, -0.14125993, -0.05426817, -0.0450663 ,\n",
      "        -0.16216709, -0.03735349, -0.15348039, -0.19941561,  0.36123517]])]\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# [10, 5, 3, 5, 10]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m Autoencoder(inputDim, hiddenLayers, neuronsPerLayer)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrainData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 54\u001b[0m, in \u001b[0;36mAutoencoder.fit\u001b[0;34m(self, x, lr, n_epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[0;32m---> 54\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 44\u001b[0m, in \u001b[0;36mAutoencoder.decode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhiddenLayers \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhiddenLayers \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 44\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb[i]\n\u001b[1;32m     45\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(z)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
