{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## João Pedro Rodrigues Freitas - 11316552"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Fazer os mini batches (train, test)\n",
    "- Fazer o one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Esta classe realiza o pre-processamento dos dados, permitindo:\n",
    "- Permite definir uma porcentagem de dados para treino\n",
    "- Embaralhar as linhas\n",
    "- Normalizar os dados (para cada coluna, de acordo com o max e min de cada coluna)\n",
    "- Obter o conjunto de treino\n",
    "- Obter o conjunto de teste\n",
    "- Obter o número de atributos (numero de colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, X: np.ndarray) -> None:\n",
    "        self.data = X\n",
    "\n",
    "\n",
    "    def getData(self) -> np.ndarray:\n",
    "        return self.data\n",
    "    \n",
    "\n",
    "    def setTrainRatio(self, ratio: float) -> None:\n",
    "        self.train_ratio = ratio\n",
    "\n",
    "\n",
    "    def getTrainRatio(self) -> float:\n",
    "        return self.train_ratio\n",
    "    \n",
    "    \n",
    "    def getAttrSize(self) -> int:\n",
    "        return self.data.shape[1]\n",
    "    \n",
    "    \n",
    "    def shuffleData(self) -> None:\n",
    "        self.data = np.random.permutation(self.data)\n",
    "\n",
    "\n",
    "    def getTrainData(self) -> np.ndarray:\n",
    "        return self.data[:int(self.data.shape[0] * self.train_ratio)]\n",
    "    \n",
    "    \n",
    "    def getTestData(self) -> np.ndarray:\n",
    "        return self.data[int(self.data.shape[0] * self.train_ratio):]\n",
    "    \n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        '''Normaliza cada atributo para o intervalo [0, 1]'''\n",
    "        for i in range(self.getAttrSize()):\n",
    "            self.data[:,i] = (self.data[:,i] - np.min(self.data[:,i])) / (np.max(self.data[:,i]) - np.min(self.data[:,i]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer\n",
    "Os layers contém as informações das camadas.\n",
    "\n",
    "Os pesos e bias são inicializados de acordo com uma distribuição uniforme\n",
    "no intervalo de -0.5 a 0.5\n",
    "\n",
    "O layer permite realizar o forward de si próprio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n_neurons: int, actv_func, inputs = None, lastLayer: bool = False) -> None:\n",
    "        self.n_neurons = n_neurons\n",
    "        self.actv_func = actv_func\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.out = None # Saída da camada\n",
    "        self.actv = None # Saída com função de ativação\n",
    "\n",
    "        self.inputs = inputs # Entradas da camada\n",
    "        self.shape = None\n",
    "        self.inputShape = None\n",
    "\n",
    "        self.lastLayer = lastLayer\n",
    "\n",
    "\n",
    "    def _setWeights(self) -> None:\n",
    "        if self.W is None and self.inputs is not None:\n",
    "            self.inputShape = self.inputs.shape\n",
    "            self.shape = (self.inputShape[-1], self.n_neurons) # Shape da matriz de pesos a ser criada\n",
    "\n",
    "            # Inicializa os pesos e bias com distribuição uniforme\n",
    "            # entre -0.5 e 0.5\n",
    "            self.W = np.random.rand(self.shape[0], self.shape[1]) - 0.5\n",
    "            self.b = np.random.rand(self.n_neurons) - 0.5\n",
    "\n",
    "\n",
    "    # Realiza o forward da camada\n",
    "    def process(self, inputs) -> None:\n",
    "        self.inputs = inputs\n",
    "\n",
    "        self._setWeights() # Inicializa os pesos e bias, caso n tenham sido inicializados\n",
    "\n",
    "        self.out = np.dot(self.inputs, self.W) + self.b\n",
    "\n",
    "        # Se for a última camada, não aplica a função de ativação\n",
    "        if not self.lastLayer:\n",
    "            self.actv = self.actv_func(self.out)\n",
    "        else:\n",
    "            self.actv = self.out\n",
    "\n",
    "\n",
    "    def getOutput(self):\n",
    "        return self.out\n",
    "    \n",
    "    \n",
    "    def getActivation(self):\n",
    "        return self.actv\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "    def __init__(self) -> None:\n",
    "        self.layers = np.array([], dtype=Layer)\n",
    "\n",
    "        self.epochs = None\n",
    "        self.lr = None\n",
    "\n",
    "        self.inputs = None # X\n",
    "        self.targets = None # X\n",
    "\n",
    "        self.outputs = []\n",
    "        self.ativations = [] # X_Hat\n",
    "\n",
    "    def addLayer(self, layer: Layer) -> None:\n",
    "        self.layers = np.append(self.layers, layer)\n",
    "\n",
    "    # TODO: separar entre encoder e decoder\n",
    "    def forward(self, inputs):\n",
    "        self.ativations = []\n",
    "        self.outputs = []\n",
    "\n",
    "        self.ativations.append(inputs)\n",
    "        self.outputs.append(inputs)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            layer.process(inputs)\n",
    "            inputs = layer.getActivation()\n",
    "            output = layer.getOutput()\n",
    "\n",
    "            self.outputs.append(output)\n",
    "            self.ativations.append(inputs)\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    # TODO: separar entre encoder e decoder\n",
    "    def backward(self) -> None:\n",
    "        i = self.layers.size\n",
    "        n = self.inputs.shape[0]\n",
    "\n",
    "        err = 2 * (self.targets - self.ativations[-1]) # x - x_hat\n",
    "\n",
    "        for layer, z in zip(self.layers[::-1], self.outputs[::-1]):\n",
    "            delta = err\n",
    "\n",
    "            if (i != self.layers.size):\n",
    "                delta *= layer.actv_func(z, derivative=True)\n",
    "\n",
    "            err = np.dot(delta, layer.W.T) # Atualiza o erro pro layer anterior\n",
    "\n",
    "            if i > 0:\n",
    "                prev_ativ = self.ativations[i-1]\n",
    "                dW = np.dot(prev_ativ.T, delta) / n\n",
    "                db = delta.mean()\n",
    "\n",
    "                layer.W += self.lr * dW\n",
    "                layer.b += self.lr * db\n",
    "\n",
    "\n",
    "            i -= 1\n",
    "        \n",
    "    def fit(self, inputs, targets, lr: float = 0.01, epochs: int = 100) -> None:\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.lr = lr\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(inputs)\n",
    "            self.backward()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}')\n",
    "                print(f'Loss: {np.mean(np.square(self.targets - self.ativations[-1]))}')\n",
    "\n",
    "\n",
    "    def predict(self, inputs) -> np.ndarray:\n",
    "        self.forward(inputs)\n",
    "        return self.ativations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de ativação\n",
    "\n",
    "Foi utilizada a função de ativação sigmoide.\n",
    "\n",
    "A função dada por 1 / (1 + np.exp(-Z)) é sensível a overflow. Desse modo, ela\n",
    "foi adaptada (mesma função do pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "    positives = x >= 0\n",
    "    negatives = ~positives\n",
    "    \n",
    "    exp_x_neg = np.exp(x[negatives])\n",
    "    \n",
    "    y = x.copy()\n",
    "    y[positives] = 1 / (1 + np.exp(-x[positives]))\n",
    "    y[negatives] = exp_x_neg / (1 + exp_x_neg)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo\n",
    "Esta função instancia a classe autoencoder.\n",
    "\n",
    "Ela recebe a dimensão dos atributos de entrada, as camadas ocultas (na parte do\n",
    "encoder) e a função de ativação.\n",
    "\n",
    "Esta função irá instanciar os layers de forma que seja espelhado, ou seja:\n",
    "\n",
    "Se inputDim = 10, e as camadas ocultas têm os tamanhos layers=[5, 3], então\n",
    "a camada com 3 neurônios será a dimensão latente, sendo tudo antes dela espelhado.\n",
    "\n",
    "Assim, ficará no formato: [10, 5, 3, 5, 10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(inputDim, layers, actv_func):\n",
    "    model = Autoencoder()\n",
    "\n",
    "    # Adiciona as camadas do encoder\n",
    "    for i in range(len(layers)):\n",
    "        model.addLayer(Layer(layers[i], actv_func))\n",
    "\n",
    "    # Adiciona as camadas do decoder\n",
    "    for i in range(len(layers)-2, -1, -1):\n",
    "        model.addLayer(Layer(layers[i], actv_func))\n",
    "\n",
    "    # Adiciona a camada de saída\n",
    "    model.addLayer(Layer(inputDim, actv_func, lastLayer = True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 1.3487445745223747\n",
      "Epoch: 10\n",
      "Loss: 0.08098388132229166\n",
      "Epoch: 20\n",
      "Loss: 0.054305783297435364\n",
      "Epoch: 30\n",
      "Loss: 0.053412814099941315\n",
      "Epoch: 40\n",
      "Loss: 0.05328875247362576\n",
      "Epoch: 50\n",
      "Loss: 0.053187049884205556\n",
      "Epoch: 60\n",
      "Loss: 0.053083641615765335\n",
      "Epoch: 70\n",
      "Loss: 0.0529775013871444\n",
      "Epoch: 80\n",
      "Loss: 0.052868373738460255\n",
      "Epoch: 90\n",
      "Loss: 0.05275602434467895\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack([np.random.normal(1, 0.5, [100,64]),\n",
    "                np.random.normal(-2, 1, [100,64]),\n",
    "                np.random.normal(3, 0.75, [100,64])])\n",
    "\n",
    "data = Data(X)\n",
    "\n",
    "data.normalize()\n",
    "data.shuffleData()\n",
    "data.setTrainRatio(0.8)\n",
    "\n",
    "inputDim = data.getAttrSize()\n",
    "\n",
    "# Número de neurônios em cada camada escondida\n",
    "# A última camada dessa lista é a dimensão latente\n",
    "# O espelhamento é feito automaticamente\n",
    "# Exemplo:\n",
    "# Para um X com 64 atributos, se hiddenLayers = [32, 16], a rede terá a seguinte estrutura:\n",
    "# [64, 32, 16, 32, 64]\n",
    "# Em que o primeiro valor é a dimensão de entrada e o último é a dimensão de saída\n",
    "hiddenLayers = [32, 16]\n",
    "\n",
    "autoencoder = createModel(inputDim, hiddenLayers, actv_func=sigmoid)\n",
    "\n",
    "# autoencoder = createModel([inputDim] + teste + [inputDim], actv_func=sigmoid)\n",
    "autoencoder.fit(data.getTrainData(), data.getTrainData(), lr=0.01, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro quadrático médio: 5.492%\n"
     ]
    }
   ],
   "source": [
    "X = data.getTestData()\n",
    "X_hat = autoencoder.predict(X)\n",
    "\n",
    "err = np.mean(np.square(X - X_hat))\n",
    "\n",
    "print(f'Erro quadrático médio: {err * 100:.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
